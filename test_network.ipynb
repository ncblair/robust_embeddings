{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.base_network import BaseNetwork\n",
    "from file_handling.load_datasets import load_mnist\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from preprocessing.noise_models import gaussian_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Lambda(lambda x: 255*x)])\n",
    "test_data = datasets.CIFAR10(root='./cifar-10', train=False, download=False, transform=transform)\n",
    "train_data = datasets.CIFAR10(root='./cifar-10', train=True, download=False, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=16, shuffle=False, num_workers=2)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=1000, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 59.,  43.,  50.,  ..., 158., 152., 148.],\n",
       "         [ 16.,   0.,  18.,  ..., 123., 119., 122.],\n",
       "         [ 25.,  16.,  49.,  ..., 118., 120., 109.],\n",
       "         ...,\n",
       "         [208., 201., 198.,  ..., 160.,  56.,  53.],\n",
       "         [180., 173., 186.,  ..., 184.,  97.,  83.],\n",
       "         [177., 168., 179.,  ..., 216., 151., 123.]],\n",
       "\n",
       "        [[ 62.,  46.,  48.,  ..., 132., 125., 124.],\n",
       "         [ 20.,   0.,   8.,  ...,  88.,  83.,  87.],\n",
       "         [ 24.,   7.,  27.,  ...,  84.,  84.,  73.],\n",
       "         ...,\n",
       "         [170., 153., 161.,  ..., 133.,  31.,  34.],\n",
       "         [139., 123., 144.,  ..., 148.,  62.,  53.],\n",
       "         [144., 129., 142.,  ..., 184., 118.,  92.]],\n",
       "\n",
       "        [[ 63.,  45.,  43.,  ..., 108., 102., 103.],\n",
       "         [ 20.,   0.,   0.,  ...,  55.,  50.,  57.],\n",
       "         [ 21.,   0.,   8.,  ...,  50.,  50.,  42.],\n",
       "         ...,\n",
       "         [ 96.,  34.,  26.,  ...,  70.,   7.,  20.],\n",
       "         [ 96.,  42.,  30.,  ...,  94.,  34.,  34.],\n",
       "         [116.,  94.,  87.,  ..., 140.,  84.,  72.]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader.dataset[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_net = BaseNetwork(\"reg_net\", [(3, 16, 5),(16,32,5),(800,100),(100,10)],\n",
    "                                [\"conv\", \"conv\", \"fc\", \"fc\"])\n",
    "# reg_net = BaseNetwork(\"reg_net\", [(3*1024,5000),(5000,100),(100,10)],\n",
    "#                                 [\"fc\", \"fc\", \"fc\"])\n",
    "reg_net_opt = optim.RMSprop(reg_net.parameters(), lr=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_net = BaseNetwork(\"emb_net\", [(3, 16, 5),(16,32,5), (800,5000),(5000,100),(100,10)],\n",
    "                                [\"conv\", \"conv\", \"emb\", \"emb\", \"fc\"])\n",
    "# emb_net = BaseNetwork(\"emb_net\", [(3*1024,5000),(5000,100),(100,10)],\n",
    "#                                 [\"emb\", \"fc\", \"fc\"])\n",
    "emb_net_opt = optim.RMSprop(emb_net.parameters(), lr=0.00005, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d13f8741675d4e18bb46ebd2bf9a736f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    16] loss: 2.31282\n",
      "[1,    32] loss: 2.29042\n",
      "[1,    48] loss: 2.26662\n",
      "[1,    64] loss: 2.26682\n",
      "[1,    80] loss: 2.21862\n",
      "[1,    96] loss: 2.18597\n",
      "[1,   112] loss: 2.16455\n",
      "[1,   128] loss: 2.22451\n",
      "[1,   144] loss: 2.16316\n",
      "[1,   160] loss: 2.10143\n",
      "[1,   176] loss: 2.12910\n",
      "[1,   192] loss: 2.09642\n",
      "[1,   208] loss: 2.08058\n",
      "[1,   224] loss: 2.05148\n",
      "[1,   240] loss: 1.99554\n",
      "[1,   256] loss: 2.09253\n",
      "[1,   272] loss: 2.03908\n",
      "[1,   288] loss: 2.09571\n",
      "[1,   304] loss: 2.04267\n",
      "[1,   320] loss: 2.03413\n",
      "[1,   336] loss: 2.08966\n",
      "[1,   352] loss: 2.03533\n",
      "[1,   368] loss: 2.02972\n",
      "[1,   384] loss: 2.00934\n",
      "[1,   400] loss: 2.01194\n",
      "[1,   416] loss: 2.01908\n",
      "[1,   432] loss: 2.06579\n",
      "[1,   448] loss: 2.00906\n",
      "[1,   464] loss: 2.00602\n",
      "[1,   480] loss: 2.06799\n",
      "[1,   496] loss: 2.03269\n",
      "[1,   512] loss: 1.96533\n",
      "[1,   528] loss: 2.02203\n",
      "[1,   544] loss: 2.03364\n",
      "[1,   560] loss: 2.04708\n",
      "[1,   576] loss: 2.02549\n",
      "[1,   592] loss: 2.02482\n",
      "[1,   608] loss: 1.99554\n",
      "[1,   624] loss: 1.97449\n",
      "[1,   640] loss: 2.04277\n",
      "[1,   656] loss: 2.08409\n",
      "[1,   672] loss: 1.98154\n",
      "[1,   688] loss: 1.93436\n",
      "[1,   704] loss: 1.98454\n",
      "[1,   720] loss: 2.01255\n",
      "[1,   736] loss: 1.87426\n",
      "[1,   752] loss: 2.08254\n",
      "[1,   768] loss: 1.95135\n",
      "[1,   784] loss: 1.92682\n",
      "[1,   800] loss: 1.99815\n",
      "[1,   816] loss: 2.00409\n",
      "[1,   832] loss: 1.94729\n",
      "[1,   848] loss: 1.99070\n",
      "[1,   864] loss: 1.92900\n",
      "[1,   880] loss: 1.93364\n",
      "[1,   896] loss: 1.99092\n",
      "[1,   912] loss: 1.93120\n",
      "[1,   928] loss: 1.92477\n",
      "[1,   944] loss: 1.98893\n",
      "[1,   960] loss: 1.96638\n",
      "[1,   976] loss: 2.00088\n",
      "[1,   992] loss: 1.91095\n",
      "[1,  1008] loss: 1.92802\n",
      "[1,  1024] loss: 1.96968\n",
      "[1,  1040] loss: 1.96193\n",
      "[1,  1056] loss: 1.96789\n",
      "[1,  1072] loss: 1.88159\n",
      "[1,  1088] loss: 1.95274\n",
      "[1,  1104] loss: 1.91175\n",
      "[1,  1120] loss: 1.91809\n",
      "[1,  1136] loss: 1.89041\n",
      "[1,  1152] loss: 1.87310\n",
      "[1,  1168] loss: 1.93791\n",
      "[1,  1184] loss: 1.90734\n",
      "[1,  1200] loss: 1.98773\n",
      "[1,  1216] loss: 1.94225\n",
      "[1,  1232] loss: 1.89092\n",
      "[1,  1248] loss: 1.89259\n",
      "[1,  1264] loss: 1.92190\n",
      "[1,  1280] loss: 1.88235\n",
      "[1,  1296] loss: 1.91976\n",
      "[1,  1312] loss: 1.83484\n",
      "[1,  1328] loss: 1.90489\n",
      "[1,  1344] loss: 1.83430\n",
      "[1,  1360] loss: 1.73406\n",
      "[1,  1376] loss: 1.93141\n",
      "[1,  1392] loss: 1.86254\n",
      "[1,  1408] loss: 1.83476\n",
      "[1,  1424] loss: 1.83104\n",
      "[1,  1440] loss: 1.88886\n",
      "[1,  1456] loss: 1.82680\n",
      "[1,  1472] loss: 1.84590\n",
      "[1,  1488] loss: 1.77554\n",
      "[1,  1504] loss: 1.82321\n",
      "[1,  1520] loss: 1.83794\n",
      "[1,  1536] loss: 1.77844\n",
      "[1,  1552] loss: 1.84313\n",
      "[1,  1568] loss: 1.87296\n",
      "[1,  1584] loss: 1.85721\n",
      "[1,  1600] loss: 1.82156\n",
      "[1,  1616] loss: 1.82822\n",
      "[1,  1632] loss: 1.76081\n",
      "[1,  1648] loss: 1.81019\n",
      "[1,  1664] loss: 1.86805\n",
      "[1,  1680] loss: 1.79575\n",
      "[1,  1696] loss: 1.88822\n",
      "[1,  1712] loss: 1.85516\n",
      "[1,  1728] loss: 1.82930\n",
      "[1,  1744] loss: 1.83397\n",
      "[1,  1760] loss: 1.87895\n",
      "[1,  1776] loss: 1.81410\n",
      "[1,  1792] loss: 1.84984\n",
      "[1,  1808] loss: 1.72455\n",
      "[1,  1824] loss: 1.84314\n",
      "[1,  1840] loss: 1.81423\n",
      "[1,  1856] loss: 1.82879\n",
      "[1,  1872] loss: 1.71502\n",
      "[1,  1888] loss: 1.77364\n",
      "[1,  1904] loss: 1.75910\n",
      "[1,  1920] loss: 1.84794\n",
      "[1,  1936] loss: 1.81505\n",
      "[1,  1952] loss: 1.73706\n",
      "[1,  1968] loss: 1.74293\n",
      "[1,  1984] loss: 1.76267\n",
      "[1,  2000] loss: 1.79376\n",
      "[1,  2016] loss: 1.81134\n",
      "[1,  2032] loss: 1.75131\n",
      "[1,  2048] loss: 1.76479\n",
      "[1,  2064] loss: 1.80910\n",
      "[1,  2080] loss: 1.77409\n",
      "[1,  2096] loss: 1.82562\n",
      "[1,  2112] loss: 1.81241\n",
      "[1,  2128] loss: 1.80345\n",
      "[1,  2144] loss: 1.65492\n",
      "[1,  2160] loss: 1.74210\n",
      "[1,  2176] loss: 1.70975\n",
      "[1,  2192] loss: 1.77576\n",
      "[1,  2208] loss: 1.79161\n",
      "[1,  2224] loss: 1.67689\n",
      "[1,  2240] loss: 1.78223\n",
      "[1,  2256] loss: 1.75715\n",
      "[1,  2272] loss: 1.76419\n",
      "[1,  2288] loss: 1.59735\n",
      "[1,  2304] loss: 1.68189\n",
      "[1,  2320] loss: 1.76392\n",
      "[1,  2336] loss: 1.75260\n",
      "[1,  2352] loss: 1.76662\n",
      "[1,  2368] loss: 1.73590\n",
      "[1,  2384] loss: 1.87852\n",
      "[1,  2400] loss: 1.72117\n",
      "[1,  2416] loss: 1.73324\n",
      "[1,  2432] loss: 1.65995\n",
      "[1,  2448] loss: 1.65374\n",
      "[1,  2464] loss: 1.77464\n",
      "[1,  2480] loss: 1.76102\n",
      "[1,  2496] loss: 1.69961\n",
      "[1,  2512] loss: 1.63743\n",
      "[1,  2528] loss: 1.79567\n",
      "[1,  2544] loss: 1.63534\n",
      "[1,  2560] loss: 1.77286\n",
      "[1,  2576] loss: 1.73262\n",
      "[1,  2592] loss: 1.70233\n",
      "[1,  2608] loss: 1.68792\n",
      "[1,  2624] loss: 1.63301\n",
      "[1,  2640] loss: 1.71803\n",
      "[1,  2656] loss: 1.61559\n",
      "[1,  2672] loss: 1.74704\n",
      "[1,  2688] loss: 1.77707\n",
      "[1,  2704] loss: 1.66459\n",
      "[1,  2720] loss: 1.69470\n",
      "[1,  2736] loss: 1.68158\n",
      "[1,  2752] loss: 1.73317\n",
      "[1,  2768] loss: 1.73425\n",
      "[1,  2784] loss: 1.68638\n",
      "[1,  2800] loss: 1.69593\n",
      "[1,  2816] loss: 1.63201\n",
      "[1,  2832] loss: 1.68746\n",
      "[1,  2848] loss: 1.68438\n",
      "[1,  2864] loss: 1.61554\n",
      "[1,  2880] loss: 1.67303\n",
      "[1,  2896] loss: 1.63105\n",
      "[1,  2912] loss: 1.73549\n",
      "[1,  2928] loss: 1.62296\n",
      "[1,  2944] loss: 1.75500\n",
      "[1,  2960] loss: 1.53962\n",
      "[1,  2976] loss: 1.63220\n",
      "[1,  2992] loss: 1.60757\n",
      "[1,  3008] loss: 1.83651\n",
      "[1,  3024] loss: 1.61068\n",
      "[1,  3040] loss: 1.71863\n",
      "[1,  3056] loss: 1.68144\n",
      "[1,  3072] loss: 1.73540\n",
      "[1,  3088] loss: 1.60363\n",
      "[1,  3104] loss: 1.58975\n",
      "[1,  3120] loss: 1.61093\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad28159e669b45c7aa6fc4226f5951b6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2,    16] loss: 1.59596\n",
      "[2,    32] loss: 1.57031\n",
      "[2,    48] loss: 1.65446\n",
      "[2,    64] loss: 1.61186\n",
      "[2,    80] loss: 1.60094\n",
      "[2,    96] loss: 1.66678\n",
      "[2,   112] loss: 1.62371\n",
      "[2,   128] loss: 1.71427\n",
      "[2,   144] loss: 1.60461\n",
      "[2,   160] loss: 1.62378\n",
      "[2,   176] loss: 1.64126\n",
      "[2,   192] loss: 1.57828\n",
      "[2,   208] loss: 1.64698\n",
      "[2,   224] loss: 1.60508\n",
      "[2,   240] loss: 1.53294\n",
      "[2,   256] loss: 1.64624\n",
      "[2,   272] loss: 1.56616\n",
      "[2,   288] loss: 1.58057\n",
      "[2,   304] loss: 1.58418\n",
      "[2,   320] loss: 1.67867\n",
      "[2,   336] loss: 1.62398\n",
      "[2,   352] loss: 1.57302\n",
      "[2,   368] loss: 1.56514\n",
      "[2,   384] loss: 1.54277\n",
      "[2,   400] loss: 1.50970\n",
      "[2,   416] loss: 1.61161\n",
      "[2,   432] loss: 1.60938\n",
      "[2,   448] loss: 1.56111\n",
      "[2,   464] loss: 1.51207\n",
      "[2,   480] loss: 1.66412\n",
      "[2,   496] loss: 1.59825\n",
      "[2,   512] loss: 1.54133\n",
      "[2,   528] loss: 1.56608\n",
      "[2,   544] loss: 1.56521\n",
      "[2,   560] loss: 1.63756\n",
      "[2,   576] loss: 1.66837\n",
      "[2,   592] loss: 1.61267\n",
      "[2,   608] loss: 1.52682\n",
      "[2,   624] loss: 1.53473\n",
      "[2,   640] loss: 1.65694\n",
      "[2,   656] loss: 1.68386\n",
      "[2,   672] loss: 1.58761\n",
      "[2,   688] loss: 1.51447\n",
      "[2,   704] loss: 1.60128\n",
      "[2,   720] loss: 1.64401\n",
      "[2,   736] loss: 1.36707\n",
      "[2,   752] loss: 1.60714\n",
      "[2,   768] loss: 1.48450\n",
      "[2,   784] loss: 1.58208\n",
      "[2,   800] loss: 1.61778\n",
      "[2,   816] loss: 1.58243\n",
      "[2,   832] loss: 1.57915\n",
      "[2,   848] loss: 1.59460\n",
      "[2,   864] loss: 1.54318\n",
      "[2,   880] loss: 1.53187\n",
      "[2,   896] loss: 1.62620\n",
      "[2,   912] loss: 1.49966\n",
      "[2,   928] loss: 1.55699\n",
      "[2,   944] loss: 1.61352\n",
      "[2,   960] loss: 1.59328\n",
      "[2,   976] loss: 1.61339\n",
      "[2,   992] loss: 1.54517\n",
      "[2,  1008] loss: 1.61813\n",
      "[2,  1024] loss: 1.56057\n",
      "[2,  1040] loss: 1.53755\n",
      "[2,  1056] loss: 1.53602\n",
      "[2,  1072] loss: 1.48038\n",
      "[2,  1088] loss: 1.51757\n",
      "[2,  1104] loss: 1.45496\n",
      "[2,  1120] loss: 1.56308\n",
      "[2,  1136] loss: 1.50840\n",
      "[2,  1152] loss: 1.47566\n",
      "[2,  1168] loss: 1.58028\n",
      "[2,  1184] loss: 1.49183\n",
      "[2,  1200] loss: 1.59164\n",
      "[2,  1216] loss: 1.52583\n",
      "[2,  1232] loss: 1.53307\n",
      "[2,  1248] loss: 1.49561\n",
      "[2,  1264] loss: 1.54890\n",
      "[2,  1280] loss: 1.54870\n",
      "[2,  1296] loss: 1.56607\n",
      "[2,  1312] loss: 1.54103\n",
      "[2,  1328] loss: 1.50147\n",
      "[2,  1344] loss: 1.57276\n",
      "[2,  1360] loss: 1.42577\n",
      "[2,  1376] loss: 1.52419\n",
      "[2,  1392] loss: 1.42956\n",
      "[2,  1408] loss: 1.47046\n",
      "[2,  1424] loss: 1.50375\n",
      "[2,  1440] loss: 1.57452\n",
      "[2,  1456] loss: 1.53203\n",
      "[2,  1472] loss: 1.48443\n",
      "[2,  1488] loss: 1.40888\n",
      "[2,  1504] loss: 1.44498\n",
      "[2,  1520] loss: 1.46202\n",
      "[2,  1536] loss: 1.41381\n",
      "[2,  1552] loss: 1.50319\n",
      "[2,  1568] loss: 1.43829\n",
      "[2,  1584] loss: 1.58454\n",
      "[2,  1600] loss: 1.49788\n",
      "[2,  1616] loss: 1.49313\n",
      "[2,  1632] loss: 1.43198\n",
      "[2,  1648] loss: 1.45664\n",
      "[2,  1664] loss: 1.51509\n",
      "[2,  1680] loss: 1.47396\n",
      "[2,  1696] loss: 1.54174\n",
      "[2,  1712] loss: 1.48771\n",
      "[2,  1728] loss: 1.46709\n",
      "[2,  1744] loss: 1.49173\n",
      "[2,  1760] loss: 1.53603\n",
      "[2,  1776] loss: 1.43416\n",
      "[2,  1792] loss: 1.53156\n",
      "[2,  1808] loss: 1.38116\n",
      "[2,  1824] loss: 1.45810\n",
      "[2,  1840] loss: 1.41065\n",
      "[2,  1856] loss: 1.51054\n",
      "[2,  1872] loss: 1.42431\n",
      "[2,  1888] loss: 1.44021\n",
      "[2,  1904] loss: 1.45660\n",
      "[2,  1920] loss: 1.53256\n",
      "[2,  1936] loss: 1.50310\n",
      "[2,  1952] loss: 1.40848\n",
      "[2,  1968] loss: 1.46162\n",
      "[2,  1984] loss: 1.45549\n",
      "[2,  2000] loss: 1.53424\n",
      "[2,  2016] loss: 1.55896\n",
      "[2,  2032] loss: 1.51687\n",
      "[2,  2048] loss: 1.48818\n",
      "[2,  2064] loss: 1.58622\n",
      "[2,  2080] loss: 1.51243\n",
      "[2,  2096] loss: 1.58609\n",
      "[2,  2112] loss: 1.61394\n",
      "[2,  2128] loss: 1.52907\n",
      "[2,  2144] loss: 1.35754\n",
      "[2,  2160] loss: 1.46854\n",
      "[2,  2176] loss: 1.45570\n",
      "[2,  2192] loss: 1.51483\n",
      "[2,  2208] loss: 1.51462\n",
      "[2,  2224] loss: 1.38602\n",
      "[2,  2240] loss: 1.50464\n",
      "[2,  2256] loss: 1.45973\n",
      "[2,  2272] loss: 1.49466\n",
      "[2,  2288] loss: 1.37928\n",
      "[2,  2304] loss: 1.41771\n",
      "[2,  2320] loss: 1.54510\n",
      "[2,  2336] loss: 1.50359\n",
      "[2,  2352] loss: 1.49743\n",
      "[2,  2368] loss: 1.46434\n",
      "[2,  2384] loss: 1.61735\n",
      "[2,  2400] loss: 1.51079\n",
      "[2,  2416] loss: 1.45724\n",
      "[2,  2432] loss: 1.37387\n",
      "[2,  2448] loss: 1.38466\n",
      "[2,  2464] loss: 1.44937\n",
      "[2,  2480] loss: 1.54507\n",
      "[2,  2496] loss: 1.44321\n",
      "[2,  2512] loss: 1.37637\n",
      "[2,  2528] loss: 1.51060\n",
      "[2,  2544] loss: 1.37793\n",
      "[2,  2560] loss: 1.49967\n",
      "[2,  2576] loss: 1.50053\n",
      "[2,  2592] loss: 1.43739\n",
      "[2,  2608] loss: 1.45810\n",
      "[2,  2624] loss: 1.36371\n",
      "[2,  2640] loss: 1.49666\n",
      "[2,  2656] loss: 1.35118\n",
      "[2,  2672] loss: 1.53377\n",
      "[2,  2688] loss: 1.49127\n",
      "[2,  2704] loss: 1.41629\n",
      "[2,  2720] loss: 1.47024\n",
      "[2,  2736] loss: 1.40815\n",
      "[2,  2752] loss: 1.48661\n",
      "[2,  2768] loss: 1.51649\n",
      "[2,  2784] loss: 1.44067\n",
      "[2,  2800] loss: 1.46239\n",
      "[2,  2816] loss: 1.40278\n",
      "[2,  2832] loss: 1.47123\n",
      "[2,  2848] loss: 1.38328\n",
      "[2,  2864] loss: 1.40952\n",
      "[2,  2880] loss: 1.41668\n",
      "[2,  2896] loss: 1.35588\n",
      "[2,  2912] loss: 1.50380\n",
      "[2,  2928] loss: 1.39590\n",
      "[2,  2944] loss: 1.49223\n",
      "[2,  2960] loss: 1.28854\n",
      "[2,  2976] loss: 1.44337\n",
      "[2,  2992] loss: 1.42918\n",
      "[2,  3008] loss: 1.58558\n",
      "[2,  3024] loss: 1.42598\n",
      "[2,  3040] loss: 1.45000\n",
      "[2,  3056] loss: 1.47919\n",
      "[2,  3072] loss: 1.50220\n",
      "[2,  3088] loss: 1.37139\n",
      "[2,  3104] loss: 1.31194\n",
      "[2,  3120] loss: 1.35083\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f47878d750946c88959d30dd97a49d8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3,    16] loss: 1.31290\n",
      "[3,    32] loss: 1.38692\n",
      "[3,    48] loss: 1.43725\n",
      "[3,    64] loss: 1.43347\n",
      "[3,    80] loss: 1.38888\n",
      "[3,    96] loss: 1.49277\n",
      "[3,   112] loss: 1.41940\n",
      "[3,   128] loss: 1.47331\n",
      "[3,   144] loss: 1.33845\n",
      "[3,   160] loss: 1.45976\n",
      "[3,   176] loss: 1.42686\n",
      "[3,   192] loss: 1.38777\n",
      "[3,   208] loss: 1.46692\n",
      "[3,   224] loss: 1.40768\n",
      "[3,   240] loss: 1.30814\n",
      "[3,   256] loss: 1.41998\n",
      "[3,   272] loss: 1.38247\n",
      "[3,   288] loss: 1.35363\n",
      "[3,   304] loss: 1.40098\n",
      "[3,   320] loss: 1.49824\n",
      "[3,   336] loss: 1.45533\n",
      "[3,   352] loss: 1.36923\n",
      "[3,   368] loss: 1.38877\n",
      "[3,   384] loss: 1.36580\n",
      "[3,   400] loss: 1.31622\n",
      "[3,   416] loss: 1.39143\n",
      "[3,   432] loss: 1.39668\n",
      "[3,   448] loss: 1.39088\n",
      "[3,   464] loss: 1.36886\n",
      "[3,   480] loss: 1.44428\n",
      "[3,   496] loss: 1.40805\n",
      "[3,   512] loss: 1.39490\n",
      "[3,   528] loss: 1.34046\n",
      "[3,   544] loss: 1.36238\n",
      "[3,   560] loss: 1.49914\n",
      "[3,   576] loss: 1.49691\n",
      "[3,   592] loss: 1.38704\n",
      "[3,   608] loss: 1.36058\n",
      "[3,   624] loss: 1.38072\n",
      "[3,   640] loss: 1.47123\n",
      "[3,   656] loss: 1.55261\n",
      "[3,   672] loss: 1.43103\n",
      "[3,   688] loss: 1.33532\n",
      "[3,   704] loss: 1.42043\n",
      "[3,   720] loss: 1.41002\n",
      "[3,   736] loss: 1.22951\n",
      "[3,   752] loss: 1.41810\n",
      "[3,   768] loss: 1.35389\n",
      "[3,   784] loss: 1.42744\n",
      "[3,   800] loss: 1.50256\n",
      "[3,   816] loss: 1.43280\n",
      "[3,   832] loss: 1.39608\n",
      "[3,   848] loss: 1.37243\n",
      "[3,   864] loss: 1.39679\n",
      "[3,   880] loss: 1.35935\n",
      "[3,   896] loss: 1.49966\n",
      "[3,   912] loss: 1.33373\n",
      "[3,   928] loss: 1.37503\n",
      "[3,   944] loss: 1.44630\n",
      "[3,   960] loss: 1.41804\n",
      "[3,   976] loss: 1.46761\n",
      "[3,   992] loss: 1.39771\n",
      "[3,  1008] loss: 1.46802\n",
      "[3,  1024] loss: 1.40317\n",
      "[3,  1040] loss: 1.33609\n",
      "[3,  1056] loss: 1.36175\n",
      "[3,  1072] loss: 1.29791\n",
      "[3,  1088] loss: 1.30862\n",
      "[3,  1104] loss: 1.28537\n",
      "[3,  1120] loss: 1.38660\n",
      "[3,  1136] loss: 1.35472\n",
      "[3,  1152] loss: 1.34347\n",
      "[3,  1168] loss: 1.43095\n",
      "[3,  1184] loss: 1.31424\n",
      "[3,  1200] loss: 1.42130\n",
      "[3,  1216] loss: 1.32785\n",
      "[3,  1232] loss: 1.39240\n",
      "[3,  1248] loss: 1.38205\n",
      "[3,  1264] loss: 1.35692\n",
      "[3,  1280] loss: 1.37813\n",
      "[3,  1296] loss: 1.38981\n",
      "[3,  1312] loss: 1.38374\n",
      "[3,  1328] loss: 1.33611\n",
      "[3,  1344] loss: 1.46210\n",
      "[3,  1360] loss: 1.27687\n",
      "[3,  1376] loss: 1.36638\n",
      "[3,  1392] loss: 1.28557\n",
      "[3,  1408] loss: 1.39162\n",
      "[3,  1424] loss: 1.38492\n",
      "[3,  1440] loss: 1.40556\n",
      "[3,  1456] loss: 1.38024\n",
      "[3,  1472] loss: 1.35612\n",
      "[3,  1488] loss: 1.28828\n",
      "[3,  1504] loss: 1.29104\n",
      "[3,  1520] loss: 1.32811\n",
      "[3,  1536] loss: 1.29341\n",
      "[3,  1552] loss: 1.33612\n",
      "[3,  1568] loss: 1.27706\n",
      "[3,  1584] loss: 1.41929\n",
      "[3,  1600] loss: 1.36779\n",
      "[3,  1616] loss: 1.35608\n",
      "[3,  1632] loss: 1.31007\n",
      "[3,  1648] loss: 1.29930\n",
      "[3,  1664] loss: 1.38784\n",
      "[3,  1680] loss: 1.35307\n",
      "[3,  1696] loss: 1.41594\n",
      "[3,  1712] loss: 1.33846\n",
      "[3,  1728] loss: 1.36184\n",
      "[3,  1744] loss: 1.37001\n",
      "[3,  1760] loss: 1.38802\n",
      "[3,  1776] loss: 1.31221\n",
      "[3,  1792] loss: 1.39230\n",
      "[3,  1808] loss: 1.24423\n",
      "[3,  1824] loss: 1.34261\n",
      "[3,  1840] loss: 1.26500\n",
      "[3,  1856] loss: 1.36938\n",
      "[3,  1872] loss: 1.30594\n",
      "[3,  1888] loss: 1.32641\n",
      "[3,  1904] loss: 1.32670\n",
      "[3,  1920] loss: 1.38790\n",
      "[3,  1936] loss: 1.35954\n",
      "[3,  1952] loss: 1.29280\n",
      "[3,  1968] loss: 1.31835\n",
      "[3,  1984] loss: 1.32556\n",
      "[3,  2000] loss: 1.40271\n",
      "[3,  2016] loss: 1.40301\n",
      "[3,  2032] loss: 1.39936\n",
      "[3,  2048] loss: 1.38972\n",
      "[3,  2064] loss: 1.48673\n",
      "[3,  2080] loss: 1.38649\n",
      "[3,  2096] loss: 1.46948\n",
      "[3,  2112] loss: 1.52654\n",
      "[3,  2128] loss: 1.40490\n",
      "[3,  2144] loss: 1.23667\n",
      "[3,  2160] loss: 1.36673\n",
      "[3,  2176] loss: 1.32614\n",
      "[3,  2192] loss: 1.38699\n",
      "[3,  2208] loss: 1.41885\n",
      "[3,  2224] loss: 1.25148\n",
      "[3,  2240] loss: 1.37260\n",
      "[3,  2256] loss: 1.36556\n",
      "[3,  2272] loss: 1.38517\n",
      "[3,  2288] loss: 1.27055\n",
      "[3,  2304] loss: 1.29502\n",
      "[3,  2320] loss: 1.39645\n",
      "[3,  2336] loss: 1.38133\n",
      "[3,  2352] loss: 1.35395\n",
      "[3,  2368] loss: 1.35704\n",
      "[3,  2384] loss: 1.48735\n",
      "[3,  2400] loss: 1.41760\n",
      "[3,  2416] loss: 1.31376\n",
      "[3,  2432] loss: 1.23323\n",
      "[3,  2448] loss: 1.27422\n",
      "[3,  2464] loss: 1.30287\n",
      "[3,  2480] loss: 1.42898\n",
      "[3,  2496] loss: 1.31657\n",
      "[3,  2512] loss: 1.24990\n",
      "[3,  2528] loss: 1.37347\n",
      "[3,  2544] loss: 1.27047\n",
      "[3,  2560] loss: 1.36165\n",
      "[3,  2576] loss: 1.39379\n",
      "[3,  2592] loss: 1.31768\n",
      "[3,  2608] loss: 1.33268\n",
      "[3,  2624] loss: 1.24529\n",
      "[3,  2640] loss: 1.35824\n",
      "[3,  2656] loss: 1.20652\n",
      "[3,  2672] loss: 1.39420\n",
      "[3,  2688] loss: 1.35875\n",
      "[3,  2704] loss: 1.30773\n",
      "[3,  2720] loss: 1.33977\n",
      "[3,  2736] loss: 1.29167\n",
      "[3,  2752] loss: 1.36678\n",
      "[3,  2768] loss: 1.37302\n",
      "[3,  2784] loss: 1.33906\n",
      "[3,  2800] loss: 1.32797\n",
      "[3,  2816] loss: 1.28633\n",
      "[3,  2832] loss: 1.38127\n",
      "[3,  2848] loss: 1.21397\n",
      "[3,  2864] loss: 1.28945\n",
      "[3,  2880] loss: 1.31212\n",
      "[3,  2896] loss: 1.24030\n",
      "[3,  2912] loss: 1.41925\n",
      "[3,  2928] loss: 1.27727\n",
      "[3,  2944] loss: 1.37642\n",
      "[3,  2960] loss: 1.17710\n",
      "[3,  2976] loss: 1.32611\n",
      "[3,  2992] loss: 1.31812\n",
      "[3,  3008] loss: 1.45252\n",
      "[3,  3024] loss: 1.30981\n",
      "[3,  3040] loss: 1.32446\n",
      "[3,  3056] loss: 1.37112\n",
      "[3,  3072] loss: 1.35097\n",
      "[3,  3088] loss: 1.25908\n",
      "[3,  3104] loss: 1.19597\n",
      "[3,  3120] loss: 1.24619\n"
     ]
    }
   ],
   "source": [
    "emb_net.train_model(train_loader, 3, emb_net_opt, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emb_net.save_model(\"saved_models/emb_net_test.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model once\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "51.73"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_net.test_model_once(test_loader, None, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model once\n",
      "Evaluating model once\n",
      "Evaluating model once\n",
      "Evaluating model once\n",
      "Evaluating model once\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[51.41, 50.84, 50.04, 49.55, 48.84]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_net.test_model(test_loader, gaussian_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3a4e4f88a6d455dbb02a2853318cb32"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    16] loss: 6.93163\n",
      "[1,    32] loss: 2.28564\n",
      "[1,    48] loss: 2.21057\n",
      "[1,    64] loss: 2.23728\n",
      "[1,    80] loss: 2.15106\n",
      "[1,    96] loss: 2.14614\n",
      "[1,   112] loss: 2.01090\n",
      "[1,   128] loss: 2.00623\n",
      "[1,   144] loss: 1.99406\n",
      "[1,   160] loss: 1.89430\n",
      "[1,   176] loss: 1.96668\n",
      "[1,   192] loss: 1.81416\n",
      "[1,   208] loss: 1.97724\n",
      "[1,   224] loss: 1.91284\n",
      "[1,   240] loss: 1.75470\n",
      "[1,   256] loss: 1.87236\n",
      "[1,   272] loss: 1.92714\n",
      "[1,   288] loss: 1.79958\n",
      "[1,   304] loss: 1.81560\n",
      "[1,   320] loss: 1.81652\n",
      "[1,   336] loss: 1.77645\n",
      "[1,   352] loss: 1.71729\n",
      "[1,   368] loss: 1.73862\n",
      "[1,   384] loss: 1.66850\n",
      "[1,   400] loss: 1.69267\n",
      "[1,   416] loss: 1.78418\n",
      "[1,   432] loss: 1.73666\n",
      "[1,   448] loss: 1.64729\n",
      "[1,   464] loss: 1.64164\n",
      "[1,   480] loss: 1.75987\n",
      "[1,   496] loss: 1.81539\n",
      "[1,   512] loss: 1.65038\n",
      "[1,   528] loss: 1.67794\n",
      "[1,   544] loss: 1.66082\n",
      "[1,   560] loss: 1.83277\n",
      "[1,   576] loss: 1.75514\n",
      "[1,   592] loss: 1.71193\n",
      "[1,   608] loss: 1.62713\n",
      "[1,   624] loss: 1.55888\n",
      "[1,   640] loss: 1.81790\n",
      "[1,   656] loss: 1.67917\n",
      "[1,   672] loss: 1.66518\n",
      "[1,   688] loss: 1.60603\n",
      "[1,   704] loss: 1.69887\n",
      "[1,   720] loss: 1.67924\n",
      "[1,   736] loss: 1.61373\n",
      "[1,   752] loss: 1.71805\n",
      "[1,   768] loss: 1.67375\n",
      "[1,   784] loss: 1.64075\n",
      "[1,   800] loss: 1.70269\n",
      "[1,   816] loss: 1.65366\n",
      "[1,   832] loss: 1.69530\n",
      "[1,   848] loss: 1.61506\n",
      "[1,   864] loss: 1.65161\n",
      "[1,   880] loss: 1.50190\n",
      "[1,   896] loss: 1.64350\n",
      "[1,   912] loss: 1.63550\n",
      "[1,   928] loss: 1.59898\n",
      "[1,   944] loss: 1.74971\n",
      "[1,   960] loss: 1.62665\n",
      "[1,   976] loss: 1.74347\n",
      "[1,   992] loss: 1.59094\n",
      "[1,  1008] loss: 1.66559\n",
      "[1,  1024] loss: 1.63122\n",
      "[1,  1040] loss: 1.51880\n",
      "[1,  1056] loss: 1.59775\n",
      "[1,  1072] loss: 1.52631\n",
      "[1,  1088] loss: 1.48297\n",
      "[1,  1104] loss: 1.54977\n",
      "[1,  1120] loss: 1.49495\n",
      "[1,  1136] loss: 1.52419\n",
      "[1,  1152] loss: 1.53256\n",
      "[1,  1168] loss: 1.68598\n",
      "[1,  1184] loss: 1.56425\n",
      "[1,  1200] loss: 1.60298\n",
      "[1,  1216] loss: 1.53071\n",
      "[1,  1232] loss: 1.58006\n",
      "[1,  1248] loss: 1.48076\n",
      "[1,  1264] loss: 1.61106\n",
      "[1,  1280] loss: 1.64743\n",
      "[1,  1296] loss: 1.56528\n",
      "[1,  1312] loss: 1.42018\n",
      "[1,  1328] loss: 1.52447\n",
      "[1,  1344] loss: 1.56321\n",
      "[1,  1360] loss: 1.44639\n",
      "[1,  1376] loss: 1.51575\n",
      "[1,  1392] loss: 1.43380\n",
      "[1,  1408] loss: 1.54299\n",
      "[1,  1424] loss: 1.70930\n",
      "[1,  1440] loss: 1.54778\n",
      "[1,  1456] loss: 1.44565\n",
      "[1,  1472] loss: 1.36795\n",
      "[1,  1488] loss: 1.48410\n",
      "[1,  1504] loss: 1.48443\n",
      "[1,  1520] loss: 1.43624\n",
      "[1,  1536] loss: 1.54464\n",
      "[1,  1552] loss: 1.42628\n",
      "[1,  1568] loss: 1.40479\n",
      "[1,  1584] loss: 1.55206\n",
      "[1,  1600] loss: 1.46298\n",
      "[1,  1616] loss: 1.41686\n",
      "[1,  1632] loss: 1.40707\n",
      "[1,  1648] loss: 1.43577\n",
      "[1,  1664] loss: 1.52656\n",
      "[1,  1680] loss: 1.43889\n",
      "[1,  1696] loss: 1.59265\n",
      "[1,  1712] loss: 1.51121\n",
      "[1,  1728] loss: 1.41774\n",
      "[1,  1744] loss: 1.54031\n",
      "[1,  1760] loss: 1.48906\n",
      "[1,  1776] loss: 1.40291\n",
      "[1,  1792] loss: 1.50341\n",
      "[1,  1808] loss: 1.42049\n",
      "[1,  1824] loss: 1.42370\n",
      "[1,  1840] loss: 1.41393\n",
      "[1,  1856] loss: 1.50750\n",
      "[1,  1872] loss: 1.41841\n",
      "[1,  1888] loss: 1.34774\n",
      "[1,  1904] loss: 1.37829\n",
      "[1,  1920] loss: 1.52331\n",
      "[1,  1936] loss: 1.49894\n",
      "[1,  1952] loss: 1.46572\n",
      "[1,  1968] loss: 1.46608\n",
      "[1,  1984] loss: 1.55881\n",
      "[1,  2000] loss: 1.51956\n",
      "[1,  2016] loss: 1.58117\n",
      "[1,  2032] loss: 1.47760\n",
      "[1,  2048] loss: 1.49748\n",
      "[1,  2064] loss: 1.49302\n",
      "[1,  2080] loss: 1.47517\n",
      "[1,  2096] loss: 1.58053\n",
      "[1,  2112] loss: 1.55211\n",
      "[1,  2128] loss: 1.56903\n",
      "[1,  2144] loss: 1.36826\n",
      "[1,  2160] loss: 1.51827\n",
      "[1,  2176] loss: 1.41017\n",
      "[1,  2192] loss: 1.46919\n",
      "[1,  2208] loss: 1.51804\n",
      "[1,  2224] loss: 1.36274\n",
      "[1,  2240] loss: 1.53113\n",
      "[1,  2256] loss: 1.49860\n",
      "[1,  2272] loss: 1.42160\n",
      "[1,  2288] loss: 1.40518\n",
      "[1,  2304] loss: 1.37285\n",
      "[1,  2320] loss: 1.49078\n",
      "[1,  2336] loss: 1.47663\n",
      "[1,  2352] loss: 1.45755\n",
      "[1,  2368] loss: 1.38280\n",
      "[1,  2384] loss: 1.55855\n",
      "[1,  2400] loss: 1.49788\n",
      "[1,  2416] loss: 1.51222\n",
      "[1,  2432] loss: 1.26654\n",
      "[1,  2448] loss: 1.47493\n",
      "[1,  2464] loss: 1.46417\n",
      "[1,  2480] loss: 1.59777\n",
      "[1,  2496] loss: 1.41999\n",
      "[1,  2512] loss: 1.37486\n",
      "[1,  2528] loss: 1.52294\n",
      "[1,  2544] loss: 1.36042\n",
      "[1,  2560] loss: 1.46366\n",
      "[1,  2576] loss: 1.50289\n",
      "[1,  2592] loss: 1.38932\n",
      "[1,  2608] loss: 1.50568\n",
      "[1,  2624] loss: 1.30897\n",
      "[1,  2640] loss: 1.43173\n",
      "[1,  2656] loss: 1.29747\n",
      "[1,  2672] loss: 1.43386\n",
      "[1,  2688] loss: 1.50221\n",
      "[1,  2704] loss: 1.37654\n",
      "[1,  2720] loss: 1.49567\n",
      "[1,  2736] loss: 1.36196\n",
      "[1,  2752] loss: 1.54316\n",
      "[1,  2768] loss: 1.53856\n",
      "[1,  2784] loss: 1.45543\n",
      "[1,  2800] loss: 1.42336\n",
      "[1,  2816] loss: 1.40554\n",
      "[1,  2832] loss: 1.35498\n",
      "[1,  2848] loss: 1.24613\n",
      "[1,  2864] loss: 1.31984\n",
      "[1,  2880] loss: 1.25509\n",
      "[1,  2896] loss: 1.41171\n",
      "[1,  2912] loss: 1.49944\n",
      "[1,  2928] loss: 1.36596\n",
      "[1,  2944] loss: 1.51216\n",
      "[1,  2960] loss: 1.39037\n",
      "[1,  2976] loss: 1.39385\n",
      "[1,  2992] loss: 1.37087\n",
      "[1,  3008] loss: 1.52754\n",
      "[1,  3024] loss: 1.33689\n",
      "[1,  3040] loss: 1.31773\n",
      "[1,  3056] loss: 1.37603\n",
      "[1,  3072] loss: 1.43999\n",
      "[1,  3088] loss: 1.37465\n",
      "[1,  3104] loss: 1.33589\n",
      "[1,  3120] loss: 1.40912\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f8b0dc258ac452a9c2ebcfb62f6121d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2,    16] loss: 1.26145\n",
      "[2,    32] loss: 1.29179\n",
      "[2,    48] loss: 1.38267\n",
      "[2,    64] loss: 1.48178\n",
      "[2,    80] loss: 1.30687\n",
      "[2,    96] loss: 1.38259\n",
      "[2,   112] loss: 1.31206\n",
      "[2,   128] loss: 1.29534\n",
      "[2,   144] loss: 1.24990\n",
      "[2,   160] loss: 1.33926\n",
      "[2,   176] loss: 1.33910\n",
      "[2,   192] loss: 1.29259\n",
      "[2,   208] loss: 1.47170\n",
      "[2,   224] loss: 1.39396\n",
      "[2,   240] loss: 1.29277\n",
      "[2,   256] loss: 1.35902\n",
      "[2,   272] loss: 1.39102\n",
      "[2,   288] loss: 1.25295\n",
      "[2,   304] loss: 1.39421\n",
      "[2,   320] loss: 1.44761\n",
      "[2,   336] loss: 1.38976\n",
      "[2,   352] loss: 1.23019\n",
      "[2,   368] loss: 1.29962\n",
      "[2,   384] loss: 1.21464\n",
      "[2,   400] loss: 1.36740\n",
      "[2,   416] loss: 1.29950\n",
      "[2,   432] loss: 1.33329\n",
      "[2,   448] loss: 1.22713\n",
      "[2,   464] loss: 1.18226\n",
      "[2,   480] loss: 1.29061\n",
      "[2,   496] loss: 1.37571\n",
      "[2,   512] loss: 1.34701\n",
      "[2,   528] loss: 1.15373\n",
      "[2,   544] loss: 1.32130\n",
      "[2,   560] loss: 1.34896\n",
      "[2,   576] loss: 1.35048\n",
      "[2,   592] loss: 1.38080\n",
      "[2,   608] loss: 1.16114\n",
      "[2,   624] loss: 1.25434\n",
      "[2,   640] loss: 1.36814\n",
      "[2,   656] loss: 1.38653\n",
      "[2,   672] loss: 1.35508\n",
      "[2,   688] loss: 1.36478\n",
      "[2,   704] loss: 1.25222\n",
      "[2,   720] loss: 1.35038\n",
      "[2,   736] loss: 1.27151\n",
      "[2,   752] loss: 1.35476\n",
      "[2,   768] loss: 1.33230\n",
      "[2,   784] loss: 1.35593\n",
      "[2,   800] loss: 1.47295\n",
      "[2,   816] loss: 1.35581\n",
      "[2,   832] loss: 1.32771\n",
      "[2,   848] loss: 1.38522\n",
      "[2,   864] loss: 1.32294\n",
      "[2,   880] loss: 1.15324\n",
      "[2,   896] loss: 1.47315\n",
      "[2,   912] loss: 1.25790\n",
      "[2,   928] loss: 1.25426\n",
      "[2,   944] loss: 1.46401\n",
      "[2,   960] loss: 1.33943\n",
      "[2,   976] loss: 1.38691\n",
      "[2,   992] loss: 1.31506\n",
      "[2,  1008] loss: 1.31498\n",
      "[2,  1024] loss: 1.23290\n",
      "[2,  1040] loss: 1.26046\n",
      "[2,  1056] loss: 1.37172\n",
      "[2,  1072] loss: 1.25886\n",
      "[2,  1088] loss: 1.19131\n",
      "[2,  1104] loss: 1.22371\n",
      "[2,  1120] loss: 1.29039\n",
      "[2,  1136] loss: 1.20218\n",
      "[2,  1152] loss: 1.35835\n",
      "[2,  1168] loss: 1.32206\n",
      "[2,  1184] loss: 1.25676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-85:\n",
      "Process Process-86:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2,  1200] loss: 1.27508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/Applications/anaconda/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Applications/anaconda/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/Applications/anaconda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-f91118da6609>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mreg_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreg_net_opt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/Adarsh/Documents/Adarsh's Files/3. JUNIOR YEAR/CS294-131/robust_embeddings/models/base_network.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(self, train_loader, epochs, opt, criterion, save)\u001b[0m\n\u001b[1;32m     65\u001b[0m                                 \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m                                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m                                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Adarsh/Documents/Adarsh's Files/3. JUNIOR YEAR/CS294-131/robust_embeddings/models/base_network.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m                         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m                         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mmax_pool2d\u001b[0;34m(input, kernel_size, stride, padding, dilation, ceil_mode, return_indices)\u001b[0m\n\u001b[1;32m    394\u001b[0m     \u001b[0mSee\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;32mclass\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaxPool2d\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdetails\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m     \"\"\"\n\u001b[0;32m--> 396\u001b[0;31m     \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool2d_with_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mceil_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_indices\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/Applications/anaconda/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Applications/anaconda/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Applications/anaconda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 110, in _worker_loop\n",
      "    data_queue.put((idx, samples))\n",
      "  File \"/Applications/anaconda/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/Applications/anaconda/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/Applications/anaconda/lib/python3.6/multiprocessing/queues.py\", line 341, in put\n",
      "    obj = _ForkingPickler.dumps(obj)\n",
      "  File \"/Applications/anaconda/lib/python3.6/multiprocessing/reduction.py\", line 51, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "  File \"/Applications/anaconda/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/Applications/anaconda/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/Applications/anaconda/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "  File \"/Applications/anaconda/lib/python3.6/site-packages/torch/multiprocessing/reductions.py\", line 128, in reduce_tensor\n",
      "    metadata = (tensor.storage_offset(), tensor.size(), tensor.stride())\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "reg_net.train_model(train_loader, 3, reg_net_opt, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reg_net.save_model(\"saved_models/reg_net_test.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reg_net.load_model(\"saved_models/reg_net_test.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model once\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "52.54"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_net.test_model_once(test_loader, None, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model once\n",
      "Evaluating model once\n",
      "Evaluating model once\n",
      "Evaluating model once\n",
      "Evaluating model once\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[50.64, 47.9, 43.43, 40.52, 38.08]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_net.test_model(test_loader, gaussian_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# emb_net.train_model(train_loader, 15, emb_net_opt, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = datasets.CIFAR10(root='../data_cifar_10', train=True,\n",
    "                                       download=False, transform=transform.ToTensor())\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testset = datasets.CIFAR10(root='../data_cifar_10', train=False,\n",
    "                                       download=False, transform=transform.ToTensor())\n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
